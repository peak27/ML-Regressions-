# Load base packages manually
library(datasets)  # For example datasets
?iris
2+2
1:100
print("Hello")
b <- 2
a <- 1
x <- c(2,4,6,8,3,5)
x
10:0
0:10
seq(15)
seq(50, 10, by = -5)
y <- c(3,5,7,9,5)
y <- c(3,5,7,9,5,4)
x+y
y <- c(3,5,7,9,5)
x+y
y <- c(3,5,7,9,5, 4)
x+y
x*5
sqrt(81)
log10(100)
rm(list = ls())
clc
cl
typeof(n1)
n1 <- 17
n1
typeof(n1)
n1 <- 15
typeof(n1)
c1 <- "PK"
c1
typeof(c1)
l1 <- TRUE
l1
typeof(l1)
l2 <- F
l2
typeof(l2)
v1 <- c(1, 2, 3, 4, 5)
v1
is.vector(v1)
v2 <- c("a", "n", "d", "y")
v2
is.vector(v2)
v3 <- c(TRUE, FALSE, FALSE, TRUE, TRUE)
v3
is.vector(v3)
is.vector(n1)
m1 <- matric(c(T, F,F,T,T,F), nrow = 3)
m1 <- matrix(c(T, F,F,T,T,F), nrow = 3)
m1
m1 <- matrix(c(T, F,F,T,T,F), nrow = 3 byrow = T)
m1 <- matrix(c(T, F,F,T,T,F), nrow = 3, byrow = T)
m1
a1 <- array(c(1:24), c(4,3,2))
a1
vNum <- (1, 2, 3)
vNum <- c(1, 2, 3)
vChar <- c("a", "b", "c")
vBool <- c(T, F, T)
df1 <- cbind(vNum, vChar, vBool)
df1
df2 <- as.data.frame(cbind(vNum, vChar, vBool))
df2
MN <- c("Kato", "NKato", "Rochester", "St. Paul")
MD <- c("OC", "Delawar", "Salisbury", "West OC")
IL <- c("California", "SoCal", "NoCal", "Chicago")
US <- cbind(MN, MD, IL)
US
USA <- as.data.frame(cbind(MN, MD, IL))
USA
list1 <- list(MN,MD,IL)
list1
list2 <- list(MN, MD, list1)
list2
m <- c(1, "2", T)
m
typeof(m)
n <- as.integer(5)
n
typeof(n)
n <- as.integer("2","4","6")
n
typeof(n)
o <- matrix(c(1:15), nrow = 3)
o
is.matrix(o)
p <- as.data.frame(matrix(c(1:20), nrow = 4))
p
is.data.frame(p)
rm(list = ls())
n1 <- 15
n1
typeof(n1)
c1 <- "PK"
c1
typeof(c1)
l1 <- TRUE
l1
typeof(l1)
l2 <- F
l2
typeof(l2)
v1 <- c(1, 2, 3, 4, 5)
v1
is.vector(v1)
v2 <- c("a", "n", "d", "y")
v2
is.vector(v2)
v3 <- c(TRUE, FALSE, FALSE, TRUE, TRUE)
v3
is.vector(v3)
is.vector(n1)
m1 <- matrix(c(T, F,F,T,T,F), nrow = 3, byrow = T)
m1
a1 <- array(c(1:24), c(4,3,2))
a1
vNum <- c(1, 2, 3)
vChar <- c("a", "b", "c")
vBool <- c(T, F, T)
df1 <- cbind(vNum, vChar, vBool)
df1
df2 <- as.data.frame(cbind(vNum, vChar, vBool))
df2
MN <- c("Kato", "NKato", "Rochester", "St. Paul")
MD <- c("OC", "Delawar", "Salisbury", "West OC")
IL <- c("California", "SoCal", "NoCal", "Chicago")
US <- cbind(MN, MD, IL)
US
USA <- as.data.frame(cbind(MN, MD, IL))
USA
list1 <- list(MN,MD,IL)
list1
list2 <- list(MN, MD, list1)
list2
m <- c(1, "2", T)
m
typeof(m)
n <- as.integer("2","4","6")
n
typeof(n)
o <- matrix(c(1:15), nrow = 3)
o
is.matrix(o)
p <- as.data.frame(matrix(c(1:20), nrow = 4))
p
is.data.frame(p)
rm(list = ls())
n1 <- 15
n1
typeof(n1)
c1 <- "PK"
c1
typeof(c1)
l1 <- TRUE
l1
typeof(l1)
l2 <- F
l2
typeof(l2)
v1 <- c(1, 2, 3, 4, 5)
v1
is.vector(v1)
v2 <- c("a", "n", "d", "y")
v2
is.vector(v2)
v3 <- c(TRUE, FALSE, FALSE, TRUE, TRUE)
v3
is.vector(v3)
is.vector(n1)
m1 <- matrix(c(T, F,F,T,T,F), nrow = 3, byrow = T)
m1
a1 <- array(c(1:24), c(4,3,2))
a1
vNum <- c(1, 2, 3)
vChar <- c("a", "b", "c")
vBool <- c(T, F, T)
df1 <- cbind(vNum, vChar, vBool)
df1
df2 <- as.data.frame(cbind(vNum, vChar, vBool))
df2
MN <- c("Kato", "NKato", "Rochester", "St. Paul")
MD <- c("OC", "Delawar", "Salisbury", "West OC")
IL <- c("California", "SoCal", "NoCal", "Chicago")
US <- cbind(MN, MD, IL)
US
USA <- as.data.frame(cbind(MN, MD, IL))
USA
list1 <- list(MN,MD,IL)
list1
list2 <- list(MN, MD, list1)
list2
m <- c(1, "2", T)
m
typeof(m)
n <- as.integer("2","4","6")
n
typeof(n)
o <- matrix(c(1:15), nrow = 3)
o
is.matrix(o)
p <- as.data.frame(matrix(c(1:20), nrow = 4))
p
is.data.frame(p)
rm(list = ls())
if(!require("pacman")) install.packages("pacman")
if(!require("pacman")) install.packages("pacman")
install.packages("tidyverse")
#titanic
?Titanic
Titanic
?iris
iris
rm(list = ls())
pacman::p_load(pacman, party, rio, tidyverse)
(df <- read_csv("F:\Users\mjpk2\OneDrive\Desktop\Documents\Fall 2019\Data Science 2019\Learning R\Ex_Files_Learning_R\Exercise Files\data\StateData.xlsx"))
(df <- read_csv("Fall 2019\Data Science 2019\Learning R\Ex_Files_Learning_R\Exercise Files\data\StateData.xlsx"))
(df <- read_csv("data\StateData.xlsx"))
diamonds%>%
select(price, color)%>%
boxplot()
pacman::p_load(pacman, tidyverse)
?diamonds
diamonds
diamonds%>%
select(price, color)%>%
boxplot()
diamonds%>%
select(color, price)%>%
boxplot()
diamonds%>%
select(color, price)%>%
plot()
diamonds%>%
select(color, price)%>%
boxplot(price ~ color,
data = .,
col = "blue")
rm(list = ls())
pacman::p_load(pacman, tidyverse)
dataset = read.csv('Salary_Data.csv')
dataset = read.csv('/Salary_Data.csv')
dataset = read.csv('\Salary_Data.csv')
dataset = read.csv('Salary_Data.csv')
dataset = read.csv('/Simple Linear Regression/Salary_Data.csv')
dataset = read.csv('Simple Linear Regression/Salary_Data.csv')
dataset = read.csv('Simple Linear Regression/Salary_Data.csv')
dataset = read.csv('Salary_Data.csv')
dataset = read.csv('Salary_Data.csv')
dataset = read.csv('Salary_Data.csv')
dataset = read.csv('Salary_Data.csv')
getwd()
setwd("F:/Users/mjpk2/OneDrive/Desktop/Documents/Spring 2020/Machine Learning (ML)/Regression/Simple Linear Regression")
dataset = read.csv('Salary_Data.csv')
View(dataset)
View(dataset)
library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split = TRUE)
test_set = subset(dataset, split = FALSE)
View(test_set)
View(test_set)
library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split = TRUE)
test_set = subset(dataset, split = FALSE)
library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split = TRUE)
test_set = subset(dataset, split = FALSE)
dataset = read.csv('Salary_Data.csv')
#Spliting Datasets into training and test data
library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split = TRUE)
test_set = subset(dataset, split = FALSE)
dataset = read.csv('Salary_Data.csv')
library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
dataset = read.csv('Salary_Data.csv'
dataset = read.csv('Salary_Data.csv')
dataset = read.csv('Salary_Data.csv')
library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split = FALSE)
library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
regressor = lm(formula = Salary ~ YearsExperience, data = training_set)
summary(regressor)
View(test_set)
View(test_set)
View(regressor)
dataset = read.csv('Salary_Data.csv')
# Spliting Datasets into training and test data
library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature scaling is done by the regreession packages so manual scaling is not required
# Fit simple linear regression model to the dataset
regressor = lm(formula = Salary ~ YearsExperience,
data = training_set)
# Predicting the Test set results
y_pred = predict(regressor, newdata = test_set)
y_pred
dataset = read.csv('Salary_Data.csv')
library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
regressor = lm(formula = Salary ~ YearsExperience, data = training_set)
# Predicting the Test set results
y_pred = predict(regressor, newdata = test_set)
y_pred
View(test_set)
View(test_set)
library(ggplot2)
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary Vs Years of Experience (training set)') +
xlab('Years of Experience') +
ylab('Salary')
#Simple Linear Regrssion
# Importing the Dataset
dataset = read.csv('Salary_Data.csv')
# Spliting Datasets into training and test data
library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature scaling is done by the regreession packages so manual scaling is not required
# Fit simple linear regression model to the dataset
regressor = lm(formula = Salary ~ YearsExperience, data = training_set)
# Predicting the Test set results
y_pred = predict(regressor, newdata = test_set)
library(ggplot2)
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red') +
geom_line( aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set$Salary)),
colour = 'blue') +
ggtitle('Salary vs Years of Experience') +
xlab('Years of Experience') +
ylab('Salary')
library(ggplot2)
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red') +
geom_line( aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set$Salary)),
colour = 'blue') +
ggtitle('Salary vs Years of Experience') +
xlab('Years of Experience') +
ylab('Salary')
library(ggplot2)
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red') +
geom_line( aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Years of Experience') +
xlab('Years of Experience') +
ylab('Salary')
#Simple Linear Regrssion
# Importing the Dataset
dataset = read.csv('Salary_Data.csv')
# Spliting Datasets into training and test data
library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature scaling is done by the regreession packages so manual scaling is not required
# Fit simple linear regression model to the dataset
regressor = lm(formula = Salary ~ YearsExperience, data = training_set)
# Predicting the Test set results
y_pred = predict(regressor, newdata = test_set)
# Visualizing the Training  set results
# install.packages('ggplot2')
library(ggplot2)
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Years of Experience (Training Set') +
xlab('Years of Experience') +
ylab('Salary')
ggplot() +
geom_point(aes(x = test_set$YearsExperience, y = test_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour =  'blue') +
ggtitle('Salary Vs Years of Exp (Test Set)') +
xlab('Years of Exp') +
ylab('Salary')
#Simple Linear Regrssion
# Importing the Dataset
dataset = read.csv('Salary_Data.csv')
# Spliting Datasets into training and test data
library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature scaling is done by the regreession packages so manual scaling is not required
# Fit simple linear regression model to the dataset
regressor = lm(formula = Salary ~ YearsExperience, data = training_set)
# Predicting the Test set results
y_pred = predict(regressor, newdata = test_set)
# Visualizing the Training  set results
# install.packages('ggplot2')
library(ggplot2)
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Years of Experience (Training Set)') +
xlab('Years of Experience') +
ylab('Salary')
#Visualizing test set results
ggplot() +
geom_point(aes(x = test_set$YearsExperience, y = test_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour =  'blue') +
ggtitle('Salary Vs Years of Exp (Test Set)') +
xlab('Years of Exp') +
ylab('Salary')
